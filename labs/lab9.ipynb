{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a26877cc-5d8b-44f8-b621-de305b9652aa",
   "metadata": {},
   "source": [
    "# 9. Keras and deep learning\n",
    "In this lab, we will learn how to use Keras to build deep learning models. We will use Keras to build a LSTM model for sentiment classification and a CNN model for digit recognition.\n",
    "You need to put in the code to complete the models in the blocks marked with `## YOUR CODE HERE` and `## END OF YOUR CODE`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b883c76f-1649-4fca-a014-d2b9a43520d0",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Before you can start using Keras, you'll need to install TensorFolw, which includes Keras as part of its core library.\n",
    "```bash\n",
    "source activate {your_env}\n",
    "pip install tensorflow\n",
    "pip install keras\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa88c4-c34c-4dba-8a7a-9d5578c6a087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f79e78b-b5cc-4aa8-a61e-12ad2fa2e3cf",
   "metadata": {},
   "source": [
    "## Basics of Keras\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "### 1. Initialize a model\n",
    "Start by creating a Sequential model and adding layers to it.\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialize a model\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# this is equivalent to the above\n",
    "#model = Sequential([\n",
    "#    Dense(64, activation='relu', input_dim=100),\n",
    "#    Dense(10, activation='softmax')\n",
    "#])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c2cdc-b3eb-45b7-a9db-dceeb103d5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c71b149c-8a46-4ff8-ac2e-89816cb5a8a4",
   "metadata": {},
   "source": [
    "### 2. Compile the model\n",
    "Compile the model with the appropriate loss function and optimizer.\n",
    "```python\n",
    "model.compile(loss='categorical_crossentropy', # loss function, binary_crossentropy for binary classification\n",
    "              optimizer='sgd', # stochastic gradient descent\n",
    "              metrics=['accuracy'])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a5a28-4bff-470b-8297-fcef27b12070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f38cc11c-b81d-472d-b1e4-4674d72f9643",
   "metadata": {},
   "source": [
    "### 3. Train the model\n",
    "Train the model with the training data.\n",
    "```python\n",
    "x_train = np.random.random((1000, 100))\n",
    "y_train = np.random.randint(2, size=(1000, 10))\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06cd8d2-f6b2-4bfd-a075-5cb30e0292fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24939455-d0da-4580-962c-f85a683a980c",
   "metadata": {},
   "source": [
    "### 4. Evaluate the model\n",
    "Evaluate the model with the test data.\n",
    "```python\n",
    "x_test = np.random.random((100, 100))\n",
    "y_test = np.random.randint(2, size=(100, 10))\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193a409-8a8e-41d1-83bb-cb470c81edb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2085601a-ad0f-4e35-b204-a4e2cc72c9b5",
   "metadata": {},
   "source": [
    "## Keras LSTM for IMDB sentiment classification\n",
    "The IMDB dataset is in `datasets/` of this repository. Use the following code the load the dataset and write a LSTM model to classify the sentiment of the reviews.\n",
    "```python\n",
    "import pandas as pd    # to load dataset\n",
    "import nltk\n",
    "from nltk.corpus import stopwords   # to get a collection of stopwords\n",
    "\n",
    "data = pd.read_csv('../datasets/IMDB.csv')\n",
    "\n",
    "custom_path = '../datasets/'\n",
    "\n",
    "# Append your custom path to the NLTK data path\n",
    "nltk.data.path.append(custom_path)\n",
    "\n",
    "nltk.download('stopwords', download_dir=custom_path)\n",
    "english_stops = set(stopwords.words('english'))\n",
    "\n",
    "x_data = data['review']       # Reviews/Input\n",
    "y_data = data['sentiment']    # Sentiment/Output\n",
    "# PRE-PROCESS REVIEW\n",
    "x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
    "x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
    "x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
    "x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f9a242-5c30-438d-a80d-2caf50daf4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22367208-ae65-4d74-90ee-c2a989f9068e",
   "metadata": {},
   "source": [
    "The tokenization of the reviews is done by the following code:\n",
    "```python\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer(num_words=10000)    # num_words is the number of words to keep based on word frequency\n",
    "tokenizer.fit_on_texts(x_data)            # fit tokenizer to our training text data\n",
    "\n",
    "# retrieve the word index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "x_data = tokenizer.texts_to_sequences(x_data)  # convert our text data to sequence of numbers\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7c6a9-5878-4da9-b510-d9272206ea82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86a0299a-454b-41f2-89e8-12a82e969c45",
   "metadata": {},
   "source": [
    "Now, complete the following code to create a LSTM model for the IMDB sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d5fa0-1a69-4115-8965-7651243ab909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, LSTM, Dense, GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "max_length = 100  # You can choose a different length\n",
    "x_data = pad_sequences(x_data, maxlen=max_length)\n",
    "\n",
    "# Convert sentiments to numerical labels\n",
    "y_data = np.where(y_data == 'positive', 1, 0)\n",
    "\n",
    "# Split data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "## YOUR CODE HERE\n",
    "# Build the RNN model\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "# Train the model\n",
    "\n",
    "## END OF YOUR CODE\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce51eed-0eea-4f50-bfe9-110745830fd5",
   "metadata": {},
   "source": [
    "## Keras CNN for Digit Recognition\n",
    "In lab 5, we use the digit dataset. Now, we will use the same dataset to train a CNN model to recognize the digits.\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('../datasets/digits/Digits_X_train.csv').values\n",
    "y_train = pd.read_csv('../datasets/digits/Digits_y_train.csv').values\n",
    "X_test  = pd.read_csv('../datasets/digits/Digits_X_test.csv').values\n",
    "y_test  = pd.read_csv('../datasets/digits/Digits_y_test.csv').values\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789ec0b-d08a-41d3-84de-09a807d162b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "213e96d5-1024-46c7-83a2-fa752fbb35e1",
   "metadata": {},
   "source": [
    "Complete the following code to create a CNN model for the digit recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56b310-a61b-464c-9aa0-9f608457a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Convolution2D, Flatten, MaxPooling2D\n",
    "\n",
    "# Reshape the data to 8 * 8 * 1\n",
    "X_train = X_train.reshape(X_train.shape[0], 8, 8, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 8, 8, 1)\n",
    "\n",
    "## YOUR CODE HERE\n",
    "# Create the model\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "# Train the model\n",
    "## END OF YOUR CODE\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
