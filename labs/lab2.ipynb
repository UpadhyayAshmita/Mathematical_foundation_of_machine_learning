{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27149138-cf32-4cdf-b71e-d1f7397530cd",
   "metadata": {},
   "source": [
    "# 2. Linear Regression and Logistic Regression\n",
    "After you have set up the git repository and the Python environment, you can start implementing the linear regression and logistic regression algorithms.\n",
    "In this lab, we will try to solve two types of problems: regression and classification. We will use the linear regression algorithm to solve the regression problem and the logistic regression algorithm to solve the classification problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f8e3a-fc3e-49be-8889-955af0e77d22",
   "metadata": {},
   "source": [
    "## 2.1 Linear Regression\n",
    "In the first part of the lab, you will implement the linear regression algorithm. The linear regression algorithm is used to predict the value of a continuous variable. The algorithm finds the best-fitting straight line through the points. The best-fitting line is the one that minimizes the sum of the squared differences between the observed values and the values predicted by the line.\n",
    "\n",
    "1. Use the jupyter notebook `lec2.ipynb` and try to import the California housing dataset.\n",
    "```python\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "california = fetch_california_housing()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e802278c-5831-4072-b28f-eb1489a1f9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4bd9f36-0889-4360-8d02-ec720642e291",
   "metadata": {},
   "source": [
    "2. Split the dataset into training and testing sets.\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(california.data, california.target, test_size=0.2, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa8e3a-32fb-4045-aa79-0db45bab32b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a10e54b-8261-408d-8cb7-b846a88d9bbd",
   "metadata": {},
   "source": [
    "3. Train the linear regression model using the training set.\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03347df9-53be-4a9b-9909-6c1f35b6c345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0da9c043-453f-4f0e-8f99-303a8fcb3d1b",
   "metadata": {},
   "source": [
    "4. Evaluate the model using the testing set.\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d9c74-fae8-4295-a371-6a22023c5e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c28a6431-6ec9-4f82-8143-380049c25988",
   "metadata": {},
   "source": [
    "5. Plot the learning curves.\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "train_sizes, train_scores, test_scores = learning_curve(lin_reg, california.data, california.target, train_sizes=np.linspace(0.1, 1.0, 10), cv=5)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.xlabel('Training examples')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Learning curves')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d30cea2-719b-42d7-ba0a-7f5b13176a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efa52eca-75e6-4bf5-b375-784961677fbc",
   "metadata": {},
   "source": [
    "6. In the repository, create a new file called `lab2.md` at `labs/lab2/` and write what you can conclude from the plot of Step 5 and what does the function `learning_curve` do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8d147-f11c-49a3-be9f-a7883f50af23",
   "metadata": {},
   "source": [
    "## 2.2 Logistic Regression\n",
    "In the second part of the lab, you will implement the logistic regression algorithm. The logistic regression algorithm is used to predict the probability of a binary outcome. The algorithm finds the best-fitting line through the points. The best-fitting line is the one that minimizes the sum of the squared differences between the observed values and the values predicted by the line.\n",
    "\n",
    "1. Load the iris dataset and select only the first two features.\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data[:, :2]\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4c52db-b06c-4ae3-b4d0-8683e3919fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d217806-b550-4735-a1d3-85af75a7b465",
   "metadata": {},
   "source": [
    "2. Split the dataset into training and testing sets.\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe6b24-eee9-4ba2-a3d8-742b85ca35d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3adb321c-22f5-4358-b0f0-a59f8ae5c6f9",
   "metadata": {},
   "source": [
    "3. Train the logistic regression model using the training set.\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ed8af-5e30-41f0-bfa4-691da7dc1453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cc623fa-9e05-4ecf-b751-da5b909bb518",
   "metadata": {},
   "source": [
    "4. Evaluate the model using the testing set.\n",
    "```python\n",
    "y_pred = log_reg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef36269-0cfe-4d2b-b87f-92feccd19591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a557a05a-3f6e-4013-91c6-463ddcafcda1",
   "metadata": {},
   "source": [
    "5. Plot the decision boundary.\n",
    "```python\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(4, 8, 500).reshape(-1, 1),\n",
    "        np.linspace(1.5, 4.5, 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"g^\")\n",
    "zz = y_proba[:, 1].reshape(x0.shape)\n",
    "contour = plt.contour(x0, x1, zz, cmap=plt.cm.brg)\n",
    "left_right = np.array([2.9, 7])\n",
    "boundary = -(log_reg.coef_[0][0] * left_right + log_reg.intercept_[0]) / log_reg.coef_[0][1]\n",
    "plt.clabel(contour, inline=1, fontsize=12)\n",
    "plt.plot(left_right, boundary, \"k--\", linewidth=3)\n",
    "plt.text(3.5, 1.5, \"Not Iris-Setosa\", fontsize=14, color=\"b\", ha=\"center\")\n",
    "plt.text(6.5, 3.5, \"Iris-Setosa\", fontsize=14, color=\"g\", ha=\"center\")\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.axis([4, 8, 1.5, 4.5])\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e73207-b09b-4f54-b5b2-f60471740002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb3db850-2c47-4633-8faa-244b9657c7ba",
   "metadata": {},
   "source": [
    "6. In the `lab2.md` at `labs/lab2/`, write what you can conclude from the plot of Step 5 and what does the function `predict_proba` do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc68bd-9a22-4a87-b786-e5d1072ac7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
